## Separate user-level notion of record and format-level

### Problems
  1. User want a natural notion like elements of a list of rows of a data frame. These are too small for R to process efficiently. Experiment with splitting data frames show that with airlines data set (30 cols) sweet spot is around 1000 - 10000
  1. Parsers work better reading bigger chunks, more than a single logical record: read.table, getline. There is no reason not to let them work that way even if the user wants to see the records one at a time. We can always split data before calling map.
  1. The only place where small records matter is when writing from a mapper or combiner to a reducer. Then we have to do what it takes for Hadoop to understand records.
  1. Excessive data coertion. If I write `mapreduce(to.dfs(mtcars), map = function(k,v) v))`, independent of vectorization or any other options that `v)` has to be the same as `mtcars)` and have the same columns and data from a subset of rows, as if we did a `split(mtcars), ...)[[i]]` 
 

### Solutions
  1. All parsers read in big chunks and all writers write in big chunks and the size of the chunk needs to be transparent to the user
  1. The data type of the first chunk read is the data type represented by the file. Right now the model is 
    1. read a record
    2. append
    3. go back to 1 until done
    4. manipulate the list thus defined (so called `structured` option)
    
  the new model should be
    
    1. read a record
    2. if it is a data frame or matrix, rbind. Otherwise c for lists and vectors
    3. go back to 1 until done
    4. don't need 4 no more
    
    That is we go from a data model where each record represents the element of a list to a model where each records represents a split of data structure.
    
  1. The vectorized mode refers to user-level notions like number of elements in a list or rows in a data frame, not records in the underlying format, be it native csv or whatever
  1. The no-coertion pledge. All data types stay the same through a mapreduce irrespective of vectorized option. In
  
  ```r
  from.dfs(mapreduce(to.dfs(keyvals(k1,v1)), 
                     map = function(k2,v2) ... keyvals(k3,v3), 
                     reduce = function(k4, vv) ... keyvals(k5, v5))) == 
  keyvals(k6, v6)
  ```
  for some valid range `r`, index `i` and some calls of the `map` and `reduce` functions
  
  ```r
  k1[r,] == k2
  v1[r,] == v2
  k3[i,] == k4 
  v3[i,] == vv[[j]] 
  k5 == k6[r,]
  v5 == v6[r,]
  ```
  for data.frames and matrices; for lists and atomic vectors:
  ```r
  k1[r] == k2
  v1[r] == v2
  k3[[i]] == k4
  v3[[i]] == vv[[j]]
  k5 == k6[r]
  v5 == v6[r]
  ```
  
