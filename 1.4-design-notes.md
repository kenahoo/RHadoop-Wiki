## Separate user-level notion of record and format-level

### Problems
  1. User want a natural notion like elements of a list of rows of a data frame. These are too small for R to process efficiently. Experiment with splitting data frames show that with airlines data set (30 cols) sweet spot is around 1000 - 10000
  2. Parsers work better reading bigger chunks, more than a single logical record: read.table, getline. There is no reason not to let them work that way even if the user wants to see the records one at a time. We can always split data before calling  
  3. The only place where small records matter is when writing from a mapper or combiner to a reducer. Then we have to do what it takes for Hadoop to understand records.
  4. Excessive data coertion. If I write `mapreduce(to.dfs(mtcars), map = function(k,v) v))`, independent of vectorization or any other options that `v)` has to be the same as `mtcars)` and have the same columns and data from a subset of rows, as if we did a `split(mtcars), ...)[[i]]` 
 

### Solutions
  1. All parsers read in big chunks and all writers write in big chunks and the size of the chunk needs to be transparent to the user
  2. The vectorized mode refers to user-level notions like number of elements in a list or rows in a data frame, not records in the underlying format, be it native csv or whatever
  3. For the shuffle phase data, use the typedbytes writer for speed on small records and fall back to native when necessary to avoid data coertion (typedbytes has no data frames, for instance). Progressively extend typedbytes to deal with more R data types.
  4. The no-coertion pledge. All data types stay the same through a mapreduce irrespective of vectorized option. In
  
  ```r
  from.dfs(mapreduce(to.dfs(keyvals(k1,v1)), 
                     map = function(k2,v2) ... keyvals(k3,v3), 
                     reduce = function(k4, vv) ... keyvals(k5, v5))) == 
  keyvals(k6, v6)
  ```
  for some valid range `r`, index `i` and some calls of the `map` and `reduce` functions
  
  ```r
  k1[r,] == k2
  v1[r,] == v2
  k3[r,] == k4 
  v3 == vv[[i]] 
  k5 == k6[r,]
  v5 == v6[r,]
  ```
  for data.frames, matrices and atomic vectors (for the latter replace `[r,] with [r]`); for lists:
  ```r
  k1[[i]] == k2
  v1[[i]] == v2
  k3[[i]] == k4
  v3 == vv[r]
  k5 == k6[r]
  v5 == v6[r]
  ```
  
